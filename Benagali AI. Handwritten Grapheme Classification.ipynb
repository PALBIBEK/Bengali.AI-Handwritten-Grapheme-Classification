{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing create_folds.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(\"../input/train.csv\")\n",
    "    print(df.head())\n",
    "    df.loc[:, 'kfold'] = -1\n",
    "\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    X = df.image_id.values\n",
    "    y = df[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
    "\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "    for fold, (trn_, val_) in enumerate(mskf.split(X, y)):\n",
    "        print(\"TRAIN: \", trn_, \"VAL: \", val_)\n",
    "        df.loc[val_, \"kfold\"] = fold\n",
    "\n",
    "    print(df.kfold.value_counts())\n",
    "    df.to_csv(\"../input/train_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing create_image_pickles.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile create_image_pickles.py\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files = glob.glob(\"../input/train_*.parquet\")\n",
    "    for f in files:\n",
    "        df = pd.read_parquet(f, engine='fastparquet')\n",
    "        image_ids = df.image_id.values\n",
    "        df = df.drop(\"image_id\", axis=1)\n",
    "        image_array = df.values\n",
    "        for j, image_id in tqdm(enumerate(image_ids), total=len(image_ids)):\n",
    "            joblib.dump(image_array[j, :], f\"../input/image_pickles/{image_id}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset.py\n",
    "\n",
    "import pandas as pd\n",
    "import albumentations\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "class BengaliDatasetTrain:\n",
    "    def __init__(self, folds, img_height, img_width, mean, std):\n",
    "        df = pd.read_csv(\"../input/train_folds.csv\")\n",
    "        df = df[[\"image_id\", \"grapheme_root\", \"vowel_diacritic\", \"consonant_diacritic\", \"kfold\"]]\n",
    "\n",
    "        df = df[df.kfold.isin(folds)].reset_index(drop=True)\n",
    "        \n",
    "        self.image_ids = df.image_id.values\n",
    "        self.grapheme_root = df.grapheme_root.values\n",
    "        self.vowel_diacritic = df.vowel_diacritic.values\n",
    "        self.consonant_diacritic = df.consonant_diacritic.values\n",
    "\n",
    "        if len(folds) == 1:\n",
    "            self.aug = albumentations.Compose([\n",
    "                albumentations.Resize(img_height, img_width, always_apply=True),\n",
    "                albumentations.Normalize(mean, std, always_apply=True)\n",
    "            ])\n",
    "        else:\n",
    "            self.aug = albumentations.Compose([\n",
    "                albumentations.Resize(img_height, img_width, always_apply=True),\n",
    "                #albumentations.ShiftScaleRotate(shift_limit=0.0625,\n",
    "                #                                scale_limit=0.1, \n",
    "                #                                rotate_limit=5,\n",
    "                #                                p=0.9),\n",
    "                albumentations.Normalize(mean, std, always_apply=True)\n",
    "            ])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image = joblib.load(f\"../input/image_pickles/{self.image_ids[item]}.pkl\")\n",
    "        image = image.reshape(137, 236).astype(float)\n",
    "        image = Image.fromarray(image).convert(\"RGB\")\n",
    "        image = self.aug(image=np.array(image))[\"image\"]\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "\n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"grapheme_root\": torch.tensor(self.grapheme_root[item], dtype=torch.long),\n",
    "            \"vowel_diacritic\": torch.tensor(self.vowel_diacritic[item], dtype=torch.long),\n",
    "            \"consonant_diacritic\": torch.tensor(self.consonant_diacritic[item], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile models.py\n",
    "\n",
    "import pretrainedmodels\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(ResNet34, self).__init__()\n",
    "        if pretrained is True:\n",
    "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=\"imagenet\")\n",
    "        else:\n",
    "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=None)\n",
    "        \n",
    "        self.l0 = nn.Linear(512, 168)\n",
    "        self.l1 = nn.Linear(512, 11)\n",
    "        self.l2 = nn.Linear(512, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, _, _, _ = x.shape\n",
    "        x = self.model.features(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        l0 = self.l0(x)\n",
    "        l1 = self.l1(x)\n",
    "        l2 = self.l2(x)\n",
    "        return l0, l1, l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_dispatcher.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_dispatcher.py\n",
    "\n",
    "import models\n",
    "\n",
    "MODEL_DISPATCHER = {\n",
    "    \"resnet34\": models.ResNet34\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "from model_dispatcher import MODEL_DISPATCHER\n",
    "from dataset import BengaliDatasetTrain\n",
    "from tqdm import tqdm\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "TRAINING_FOLDS_CSV = os.environ.get(\"TRAINING_FOLDS_CSV\")\n",
    "\n",
    "IMG_HEIGHT = int(os.environ.get(\"IMG_HEIGHT\"))\n",
    "IMG_WIDTH = int(os.environ.get(\"IMG_WIDTH\"))\n",
    "EPOCHS = int(os.environ.get(\"EPOCHS\"))\n",
    "\n",
    "TRAIN_BATCH_SIZE = int(os.environ.get(\"TRAIN_BATCH_SIZE\"))\n",
    "TEST_BATCH_SIZE = int(os.environ.get(\"TEST_BATCH_SIZE\"))\n",
    "\n",
    "MODEL_MEAN = ast.literal_eval(os.environ.get(\"MODEL_MEAN\"))\n",
    "MODEL_STD = ast.literal_eval(os.environ.get(\"MODEL_STD\"))\n",
    "\n",
    "TRAINING_FOLDS = ast.literal_eval(os.environ.get(\"TRAINING_FOLDS\"))\n",
    "VALIDATION_FOLDS = ast.literal_eval(os.environ.get(\"VALIDATION_FOLDS\"))\n",
    "BASE_MODEL = os.environ.get(\"BASE_MODEL\")\n",
    "\n",
    "\n",
    "\n",
    "def macro_recall(pred_y, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    \n",
    "    pred_y = torch.split(pred_y, [n_grapheme, n_vowel, n_consonant], dim=1)\n",
    "    pred_labels = [torch.argmax(py, dim=1).cpu().numpy() for py in pred_y]\n",
    "\n",
    "    y = y.cpu().numpy()\n",
    "\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y[:, 0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y[:, 1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y[:, 2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, 'f'total {final_score}, y {y.shape}')\n",
    "    \n",
    "    return final_score\n",
    "\n",
    "\n",
    "def loss_fn(outputs, targets):\n",
    "    o1, o2, o3 = outputs\n",
    "    t1, t2, t3 = targets\n",
    "    l1 = nn.CrossEntropyLoss()(o1, t1)\n",
    "    l2 = nn.CrossEntropyLoss()(o2, t2)\n",
    "    l3 = nn.CrossEntropyLoss()(o3, t3)\n",
    "    return (l1 + l2 + l3) / 3\n",
    "\n",
    "\n",
    "\n",
    "def train(dataset, data_loader, model, optimizer):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    counter = 0\n",
    "    final_outputs = []\n",
    "    final_targets = []\n",
    "\n",
    "    for bi, d in tqdm(enumerate(data_loader), total=int(len(dataset)/data_loader.batch_size)):\n",
    "        counter = counter + 1\n",
    "        image = d[\"image\"]\n",
    "        grapheme_root = d[\"grapheme_root\"]\n",
    "        vowel_diacritic = d[\"vowel_diacritic\"]\n",
    "        consonant_diacritic = d[\"consonant_diacritic\"]\n",
    "\n",
    "        image = image.to(DEVICE, dtype=torch.float)\n",
    "        grapheme_root = grapheme_root.to(DEVICE, dtype=torch.long)\n",
    "        vowel_diacritic = vowel_diacritic.to(DEVICE, dtype=torch.long)\n",
    "        consonant_diacritic = consonant_diacritic.to(DEVICE, dtype=torch.long)\n",
    "        \n",
    "        print(image.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        targets = (grapheme_root, vowel_diacritic, consonant_diacritic)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        final_loss += loss\n",
    "\n",
    "        o1, o2, o3 = outputs\n",
    "        t1, t2, t3 = targets\n",
    "        final_outputs.append(torch.cat((o1,o2,o3), dim=1))\n",
    "        final_targets.append(torch.stack((t1,t2,t3), dim=1))\n",
    "\n",
    "        #if bi % 10 == 0:\n",
    "        #    break\n",
    "    final_outputs = torch.cat(final_outputs)\n",
    "    final_targets = torch.cat(final_targets)\n",
    "\n",
    "    print(\"=================Train=================\")\n",
    "    macro_recall_score = macro_recall(final_outputs, final_targets)\n",
    "    \n",
    "    return final_loss/counter , macro_recall_score\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(dataset, data_loader, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        final_loss = 0\n",
    "        counter = 0\n",
    "        final_outputs = []\n",
    "        final_targets = []\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=int(len(dataset)/data_loader.batch_size)):\n",
    "            counter = counter + 1\n",
    "            image = d[\"image\"]\n",
    "            grapheme_root = d[\"grapheme_root\"]\n",
    "            vowel_diacritic = d[\"vowel_diacritic\"]\n",
    "            consonant_diacritic = d[\"consonant_diacritic\"]\n",
    "\n",
    "            image = image.to(DEVICE, dtype=torch.float)\n",
    "            grapheme_root = grapheme_root.to(DEVICE, dtype=torch.long)\n",
    "            vowel_diacritic = vowel_diacritic.to(DEVICE, dtype=torch.long)\n",
    "            consonant_diacritic = consonant_diacritic.to(DEVICE, dtype=torch.long)\n",
    "\n",
    "            outputs = model(image)\n",
    "            targets = (grapheme_root, vowel_diacritic, consonant_diacritic)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            final_loss += loss\n",
    "\n",
    "            o1, o2, o3 = outputs\n",
    "            t1, t2, t3 = targets\n",
    "            #print(t1.shape)\n",
    "            final_outputs.append(torch.cat((o1,o2,o3), dim=1))\n",
    "            final_targets.append(torch.stack((t1,t2,t3), dim=1))\n",
    "        \n",
    "        final_outputs = torch.cat(final_outputs)\n",
    "        final_targets = torch.cat(final_targets)\n",
    "\n",
    "        print(\"=================Train=================\")\n",
    "        macro_recall_score = macro_recall(final_outputs, final_targets)\n",
    "\n",
    "    return final_loss/counter , macro_recall_score\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    model = MODEL_DISPATCHER[BASE_MODEL](pretrained=True)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    train_dataset = BengaliDatasetTrain(\n",
    "        folds=TRAINING_FOLDS,\n",
    "        img_height = IMG_HEIGHT,\n",
    "        img_width = IMG_WIDTH,\n",
    "        mean = MODEL_MEAN,\n",
    "        std = MODEL_STD\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size= TRAIN_BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_dataset = BengaliDatasetTrain(\n",
    "        folds=VALIDATION_FOLDS,\n",
    "        img_height = IMG_HEIGHT,\n",
    "        img_width = IMG_WIDTH,\n",
    "        mean = MODEL_MEAN,\n",
    "        std = MODEL_STD\n",
    "    )\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size= TEST_BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                            mode=\"min\", \n",
    "                                                            patience=5, \n",
    "                                                            factor=0.3,verbose=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "    #if torch.cuda.device_count() > 1:\n",
    "    #    model = nn.DataParallel(model)\n",
    "\n",
    "    best_score = -1\n",
    "\n",
    "    print(\"FOLD : \", VALIDATION_FOLDS[0] )\n",
    "    \n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "\n",
    "        train_loss, train_score = train(train_dataset,train_loader, model, optimizer)\n",
    "        val_loss, val_score = evaluate(valid_dataset, valid_loader, model)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        \n",
    "\n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            torch.save(model.state_dict(), f\"{BASE_MODEL}_fold{VALIDATION_FOLDS[0]}.pth\")\n",
    "\n",
    "        epoch_len = len(str(EPOCHS))\n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{EPOCHS:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'train_score: {train_score:.5f} ' +\n",
    "                     f'valid_loss: {val_loss:.5f} ' +\n",
    "                     f'valid_score: {val_score:.5f}'\n",
    "                    )\n",
    "        \n",
    "        print(print_msg)\n",
    "\n",
    "        early_stopping(val_score, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    "\n",
    "export IMG_HEIGHT=137\n",
    "export IMG_WIDTH=236\n",
    "export EPOCHS=50\n",
    "export TRAIN_BATCH_SIZE=64\n",
    "export TEST_BATCH_SIZE=64\n",
    "export MODEL_MEAN=\"(0.485, 0.456, 0.406)\"\n",
    "export MODEL_STD=\"(0.229, 0.224, 0.225)\"\n",
    "export BASE_MODEL=\"resnet34\"\n",
    "export TRAINING_FOLDS_CSV=\"../input/train_folds.csv\"\n",
    "\n",
    "\n",
    "export TRAINING_FOLDS=\"(0,1,2,3)\"\n",
    "export VALIDATION_FOLDS=\"(4,)\"\n",
    "python3 train.py\n",
    "\n",
    "export TRAINING_FOLDS=\"(0,1,2,4)\"\n",
    "export VALIDATION_FOLDS=\"(3,)\"\n",
    "python3 train.py\n",
    "\n",
    "export TRAINING_FOLDS=\"(0,1,3,4)\"\n",
    "export VALIDATION_FOLDS=\"(2,)\"\n",
    "python3 train.py\n",
    "\n",
    "export TRAINING_FOLDS=\"(0,2,3,4)\"\n",
    "export VALIDATION_FOLDS=\"(1,)\"\n",
    "python3 train.py\n",
    "\n",
    "export TRAINING_FOLDS=\"(1,2,3,4)\"\n",
    "export VALIDATION_FOLDS=\"(0,)\"\n",
    "python3 train.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "pt_models = \"../input/pretrained-models/pretrained-models.pytorch-master/\"\n",
    "sys.path.insert(0, pt_models)\n",
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_MEAN = (0.485, 0.456, 0.406)\n",
    "MODEL_STD = (0.229, 0.224, 0.225)\n",
    "IMG_HEIGHT = 137\n",
    "IMG_WIDTH = 236\n",
    "DEVICE=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(ResNet34, self).__init__()\n",
    "        if pretrained is True:\n",
    "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=\"imagenet\")\n",
    "        else:\n",
    "            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=None)\n",
    "        \n",
    "        self.l0 = nn.Linear(512, 168)\n",
    "        self.l1 = nn.Linear(512, 11)\n",
    "        self.l2 = nn.Linear(512, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, _, _, _ = x.shape\n",
    "        x = self.model.features(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        l0 = self.l0(x)\n",
    "        l1 = self.l1(x)\n",
    "        l2 = self.l2(x)\n",
    "        return l0, l1, l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliDatasetTest:\n",
    "    def __init__(self, df, img_height, img_width, mean, std):\n",
    "        \n",
    "        self.image_ids = df.image_id.values\n",
    "        self.img_arr = df.iloc[:, 1:].values\n",
    "\n",
    "        self.aug = albumentations.Compose([\n",
    "            albumentations.Resize(img_height, img_width, always_apply=True),\n",
    "            albumentations.Normalize(mean, std, always_apply=True)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image = self.img_arr[item, :]\n",
    "        img_id = self.image_ids[item]\n",
    "        \n",
    "        image = image.reshape(137, 236).astype(float)\n",
    "        image = Image.fromarray(image).convert(\"RGB\")\n",
    "        image = self.aug(image=np.array(image))[\"image\"]\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        \n",
    "\n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"image_id\": img_id\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict():\n",
    "    g_pred, v_pred, c_pred = [], [], []\n",
    "    img_ids_list = [] \n",
    "    \n",
    "    for file_idx in range(4):\n",
    "        df = pd.read_parquet(f\"../input/bengaliai-cv19/test_image_data_{file_idx}.parquet\")\n",
    "\n",
    "        dataset = BengaliDatasetTest(df=df,\n",
    "                                    img_height=IMG_HEIGHT,\n",
    "                                    img_width=IMG_WIDTH,\n",
    "                                    mean=MODEL_MEAN,\n",
    "                                    std=MODEL_STD)\n",
    "\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size= TEST_BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "        for bi, d in enumerate(data_loader):\n",
    "            image = d[\"image\"]\n",
    "            img_id = d[\"image_id\"]\n",
    "            image = image.to(DEVICE, dtype=torch.float)\n",
    "\n",
    "            g, v, c = model(image)\n",
    "            #g = np.argmax(g.cpu().detach().numpy(), axis=1)\n",
    "            #v = np.argmax(v.cpu().detach().numpy(), axis=1)\n",
    "            #c = np.argmax(c.cpu().detach().numpy(), axis=1)\n",
    "\n",
    "            for ii, imid in enumerate(img_id):\n",
    "                g_pred.append(g[ii].cpu().detach().numpy())\n",
    "                v_pred.append(v[ii].cpu().detach().numpy())\n",
    "                c_pred.append(c[ii].cpu().detach().numpy())\n",
    "                img_ids_list.append(imid)\n",
    "        \n",
    "    return g_pred, v_pred, c_pred, img_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet34(pretrained=False)\n",
    "TEST_BATCH_SIZE = 32\n",
    "\n",
    "final_g_pred = []\n",
    "final_v_pred = []\n",
    "final_c_pred = []\n",
    "final_img_ids = []\n",
    "\n",
    "for i in range(5):\n",
    "    model.load_state_dict(torch.load(f\"../input/resnet34weights/resnet34_fold{i}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    g_pred, v_pred, c_pred, img_ids_list = model_predict()\n",
    "    \n",
    "    final_g_pred.append(g_pred)\n",
    "    final_v_pred.append(v_pred)\n",
    "    final_c_pred.append(c_pred)\n",
    "    if i == 0:\n",
    "        final_img_ids.extend(img_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Test_0',\n",
       " 'Test_1',\n",
       " 'Test_2',\n",
       " 'Test_3',\n",
       " 'Test_4',\n",
       " 'Test_5',\n",
       " 'Test_6',\n",
       " 'Test_7',\n",
       " 'Test_8',\n",
       " 'Test_9',\n",
       " 'Test_10',\n",
       " 'Test_11']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_g = np.argmax(np.mean(np.array(final_g_pred), axis=0), axis=1)\n",
    "final_v = np.argmax(np.mean(np.array(final_v_pred), axis=0), axis=1)\n",
    "final_c = np.argmax(np.mean(np.array(final_c_pred), axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Test_0',\n",
       " 'Test_1',\n",
       " 'Test_2',\n",
       " 'Test_3',\n",
       " 'Test_4',\n",
       " 'Test_5',\n",
       " 'Test_6',\n",
       " 'Test_7',\n",
       " 'Test_8',\n",
       " 'Test_9',\n",
       " 'Test_10',\n",
       " 'Test_11']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_img_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for ii, imid in enumerate(final_img_ids):\n",
    "    predictions.append((f\"{imid}_grapheme_root\", final_g[ii]))\n",
    "    predictions.append((f\"{imid}_vowel_diacritic\", final_v[ii]))\n",
    "    predictions.append((f\"{imid}_consonant_diacritic\", final_c[ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(predictions, columns=[\"row_id\", \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_0_grapheme_root</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_0_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_0_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_1_grapheme_root</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_1_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Test_1_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Test_2_grapheme_root</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Test_2_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Test_2_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Test_3_grapheme_root</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Test_3_vowel_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Test_3_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Test_4_grapheme_root</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Test_4_vowel_diacritic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Test_4_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Test_5_grapheme_root</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Test_5_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Test_5_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Test_6_grapheme_root</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Test_6_vowel_diacritic</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Test_6_consonant_diacritic</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Test_7_grapheme_root</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Test_7_vowel_diacritic</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Test_7_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Test_8_grapheme_root</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Test_8_vowel_diacritic</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Test_8_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Test_9_grapheme_root</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Test_9_vowel_diacritic</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Test_9_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Test_10_grapheme_root</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Test_10_vowel_diacritic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Test_10_consonant_diacritic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Test_11_grapheme_root</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Test_11_vowel_diacritic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Test_11_consonant_diacritic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         row_id  target\n",
       "0          Test_0_grapheme_root       3\n",
       "1        Test_0_vowel_diacritic       0\n",
       "2    Test_0_consonant_diacritic       0\n",
       "3          Test_1_grapheme_root      93\n",
       "4        Test_1_vowel_diacritic       2\n",
       "5    Test_1_consonant_diacritic       0\n",
       "6          Test_2_grapheme_root      19\n",
       "7        Test_2_vowel_diacritic       0\n",
       "8    Test_2_consonant_diacritic       0\n",
       "9          Test_3_grapheme_root     115\n",
       "10       Test_3_vowel_diacritic       0\n",
       "11   Test_3_consonant_diacritic       0\n",
       "12         Test_4_grapheme_root      55\n",
       "13       Test_4_vowel_diacritic       4\n",
       "14   Test_4_consonant_diacritic       0\n",
       "15         Test_5_grapheme_root     115\n",
       "16       Test_5_vowel_diacritic       2\n",
       "17   Test_5_consonant_diacritic       0\n",
       "18         Test_6_grapheme_root     147\n",
       "19       Test_6_vowel_diacritic       9\n",
       "20   Test_6_consonant_diacritic       5\n",
       "21         Test_7_grapheme_root     137\n",
       "22       Test_7_vowel_diacritic       7\n",
       "23   Test_7_consonant_diacritic       0\n",
       "24         Test_8_grapheme_root     119\n",
       "25       Test_8_vowel_diacritic       9\n",
       "26   Test_8_consonant_diacritic       0\n",
       "27         Test_9_grapheme_root     133\n",
       "28       Test_9_vowel_diacritic      10\n",
       "29   Test_9_consonant_diacritic       0\n",
       "30        Test_10_grapheme_root     148\n",
       "31      Test_10_vowel_diacritic       1\n",
       "32  Test_10_consonant_diacritic       4\n",
       "33        Test_11_grapheme_root      21\n",
       "34      Test_11_vowel_diacritic       2\n",
       "35  Test_11_consonant_diacritic       0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
